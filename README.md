# Introduction 
This project shows how you can copy a file to Azure Storage datalake and to a workspace in Databricks.

# Getting Started
1. Deploy Databricks
2. Deploy Datalake Storage
3. Create Repo and put those files in the Repo
4. Create a Variable Group in Pipeline->Library called: databricks-project (optional)
5. Connect the Variable Group to the Azure Keyvault and add all the variables (optional)
7. Create Variables on the pipeline and add variables
8. Run Pipeline

# Pipeline Run

![image](https://user-images.githubusercontent.com/98498191/232304892-d8c69cfb-c283-4ecb-80d6-361d10cd5aa2.png)
